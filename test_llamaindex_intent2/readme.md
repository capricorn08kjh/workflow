문서를 분석한 결과, LlamaIndex 기반 LLM 시스템의 정형 데이터 질의 처리 워크플로우를 파이썬으로 구현하겠습니다. 이 시스템은 자연어 질문을 받아 의도를 분류하고, 필요에 따라 데이터베이스 조회나 문서 검색을 수행하여 표나 차트로 결과를 제공합니다.LlamaIndex 기반 LLM 시스템을 구현했습니다. 이 시스템은 문서에서 설명된 워크플로우를 완전히 구현하며, 다음과 같은 기능을 제공합니다:

## 주요 특징

### 1. **의도 분류 시스템**
- **정형 데이터 질의**: 데이터베이스 조회가 필요한 질문
- **문서 검색**: 회의록, 보고서 등에서 특정 정보 찾기
- **일반 질의**: 기타 질문들

### 2. **구현된 예상 쿼리들**
문서에서 제시된 쿼리와 추가 쿼리들:
- ✅ "공정별 실적을 찾아줘"
- ✅ "회의록 중 김영철씨가 언급된 것을 찾아줘"
- ✅ "4월 월간보고서와 결산 실적을 같이 보여줘"
- 🆕 "분기별 매출 추이를 보여줘"
- 🆕 "부서별 예산 사용 현황을 알려줘"

### 3. **핵심 구성요소**

**MockLLM 클래스**: 실제 LLM 역할을 시뮬레이션
- 자연어를 SQL로 변환
- 의도 분류 및 엔티티 추출
- 최종 응답 생성

**DatabaseManager**: 데이터베이스 관리
- SQLite 기반 데모 데이터베이스
- 공정실적, 분기실적, 월간보고서, 결산실적, 부서예산 테이블

**DocumentSearchManager**: 문서 검색
- 회의록, 보고서 등의 텍스트 문서 검색
- 키워드 기반 검색 기능

**ChartGenerator**: 시각화
- matplotlib/seaborn을 이용한 차트 생성
- 막대 차트, 선 차트, 복합 차트 지원

### 4. **워크플로우**
1. **의도 분류**: 사용자 질문 분석
2. **SQL 생성**: 자연어를 SQL 쿼리로 변환
3. **DB 조회**: 실제 데이터베이스에서 데이터 조회
4. **시각화**: 표 또는 차트 형태로 결과 준비
5. **응답 생성**: 최종 사용자 응답 구성

### 5. **실행 방법**

```python
# 자동 데모 실행
demo_system()

# 대화형 모드
interactive_demo()
```

## 실제 환경에서 사용하려면

실제 프로덕션 환경에서는 주석 처리된 LlamaIndex 라이브러리들을 설치하고 활성화해야 합니다:

```bash
pip install llama-index
pip install openai
pip install sqlalchemy
```

그리고 실제 OpenAI API 키를 설정하고 MockLLM 대신 실제 LLM을 사용하면 됩니다.

이 구현은 문서에서 설명한 모든 핵심 기능을 포함하며, 확장 가능한 아키텍처로 설계되어 있어 실제 기업 환경에서도 활용할 수 있습니다.
